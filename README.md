![image](https://user-images.githubusercontent.com/113231185/213877261-b7715257-75f0-4768-9d08-df66326a1e14.png)


## Context
Recognizing things in their natural settings is one of the most fascinating challenges in the field of deep learning.

The `SVHN` dataset includes approximately 600,000 digits that have been identified and were `clipped` from `street-level photographs`. It has been put to use in the `neural networks` that Google has developed in order to enhance the quality of maps by automatically`trancribing address numbers` from individual pixel clusters. The `combination` of the `transcribed number` and the `known street address` makes it easier to locate the building that the number represents.

## Objective
Develop a CNN model that is capable of `recognizing the digits` that are shown in the photos

## Dataset
To `reduce` the amount of `time spent computing`, we will only utilize a `portion` of the whole original data. The dataset is supplied in the form of a `.h5 file`. All of the `fundamental preprocessing procedures` have been `completed`.

## Visualization
![image](https://user-images.githubusercontent.com/113231185/213877494-f64fbb40-32ce-44e2-b4f2-fca3be610d8c.png)

## Performance Visualization
![image](https://user-images.githubusercontent.com/113231185/213877575-406b972a-13ba-4d27-92df-223970e0009e.png)


